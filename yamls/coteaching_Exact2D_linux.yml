project_root: /home/mgilani/sshfs/ # /home/mgilani/sshfs/Minh_Mahdi_mod/prostate_cancer_classification
tasks: [ 'cls', ]
tasks_num_class: [ 2, ]
input_channels: [ 1, ] ############################################
num_workers: 14
model_name: coteaching # vanilla
self_train: False
variational: False
multitask: False
is_eval: False
val_size: .4
split_random_state: 26

paths: # 'exp_name' will be replaced by actual experiment name
  log_dir: experiments/exp_name/logs
  result_dir: experiments/exp_name/results
  checkpoint_dir: experiments/exp_name/checkpoints
  self_train_checkpoint: 'ckpt2/inception/SelfTime/ProstateTeUS/magnitude_warp_time_warp/0.2_3C/0/backbone_best.tar'

data_source:
  dataset: Exact_patched #Exact2D_286x15
  data_root: /home/mgilani/data/Exact # /home/mgilani/sshfs/data
  train_set:  Exact_UVA_patches_400_100_100_10-08-2021.mat # Exact_UVA_patches_400_100_100_Birthday2021_dynamic.mat
  # ExactV2_withInv_D3_ds5_all_2021-06-10.mat # BKcomp_D3_ds5_all_2021-29-7.mat # BKcomp_D1_ds5_all_2021-2-7.mat
  test_set:  Exact_UVA_patches_400_100_100_10-08-2021.mat # Exact_UVA_patches_400_100_100_Birthday2021_dynamic.mat
  # ExactV2_withInv_D3_ds5_all_2021-06-10.mat # BKcomp_D3_ds5_all_2021-29-7.mat # BKcomp_D1_ds5_all_2021-2-7.mat
  unlabelled_set: none #unlabelled/BK_RF_P1_140_balance__20210203-175808_unsup.npy
  IDloading_dynmc: False
  dynmc_dataroot:  /home/mgilani/data/Exact/UVA_multiframe #/home/mgilani/sshfs_data # C:/Users/Mahdi/Desktop/Exact/UVA_multiframe #D:/Exact/patches/UVA_multiframe

# Tunable (iteratively) hyper-parameters
seed: 0
n_epochs: 100
epoch_start_correct: 1000
epoch_label_anneal: 1000
total_iters: 20000
#backbone: [ Inception, Inception ]  # SimConv4 Inception resnet_ucr
backbone: [ resnet, resnet ]  # SimConv4 Inception resnet
#backbone: [ resvit, resvit ]
#backbone: [ densenet, densenet ]
#backbone: [ unet_modf, unet_modf ]
#backbone: [ Classifier3L_2D, Classifier3L_2D ]  # SimConv4 Inception resnet_ucr Classifier3L
exp_name: coteaching
exp_suffix: ''
test_batch_size: 32
train_batch_size:  32
lr: 1e-4
normalize_input: none
temperature: .5
#aug_type: ['Flip','Rotate', 'ShearX','ShearY']
aug_type: 'none'
aug_prob: 0.2
unsup_aug_type: [ 'magnitude_warp', 'time_warp', 'window_slice', 'window_warp' ]  # 'none', 'scaling'
loss_name: 'ce'  # 'gce'
min_inv: .7

core_wise:
  activation: False
  num_gradual: 30

random_patch:
  activation: False
  patch_siz: 32

train:
  loss_coefficients: [ 1., 0.1 ]
  n_views: 1
  lr_scheduler:
    patience: 999
    trials: 0
    epoch_decay_start: 50
  resume: False
  retrain_resume: False
  policy_iter: best
  which_iter: warmup
  init_method: equal
  log_interval: 1
  val_interval: 1
  switch_core_no: 0
  coteaching:
    num_gradual: 6
    exponent: 1
    forget_rate: .4
    use_plus: False
    relax: False  # False True

arch:
  # inception
  num_blocks: 5
  out_channels: 16 # 16
  # resnet
  mid_channels: 32
  num_positions: 12

tensorboard:
  flush_secs: 10
  filename_suffix: ''

test:
  test_interval: 1
  which_iter: best

abstention:
  learn_epochs: 5
  abst_rate: 0.1
  alpha_final: 1.
  alpha_init_factor: 64.
  pid_tunings: [.1, .1, .05]
elr_alpha: 0
elr_beta: .7

correcting:
  inv_dif_thr: .1
  prob_thr: .85