project_root: /raid/home/minht/projects/prostate_teus/ProstateCancerClassificationV1
tasks: [ 'cls', ]
tasks_num_class: [ 2, ]
input_channels: [ 1, ]
num_workers: 24
model_name: coteaching
self_train: False
variational: False
multitask: False
is_eval: False

paths: # 'exp_name' will be replaced by actual experiment name
  log_dir: experiments/exp_name/logs
  result_dir: experiments/exp_name/results
  checkpoint_dir: experiments/exp_name/checkpoints
  self_train_checkpoint: 'ckpt2/inception/SelfTime/ProstateTeUS/magnitude_warp_time_warp/0.2_3C/0/backbone_best.tar'

data_source:
  dataset: ProstateTeUS
  data_root: datasets
  train_set: BK_RF_P1_140_balance__20210203-175808_mimic.pkl  # BK_RF_P1_140_balance__20201127-104536.mat
  test_set: BK_RF_P1_140_balance__20210203-175808_mimic.pkl

# Tunable (iteratively) hyper-parameters
seed: 0
n_epochs: 100
total_iters: 20000
backbone: [ Inception, Inception ]  # SimConv4 Inception resnet_ucr
#backbone: [ resnet, resnet ]  # SimConv4 Inception resnet
#backbone: [ Classifier3L, Classifier3L ]  # SimConv4 Inception resnet_ucr Classifier3L
exp_name: coteaching
exp_suffix: ''
test_batch_size: 2048
train_batch_size: 2048
lr: 1e-4
normalize_input: none
temperature: .5
aug_type: [ 'magnitude_warp', 'time_warp', 'window_slice', 'window_warp' ]  # 'none', 'scaling'
#aug_type: 'none'
loss_name: 'gce'  # 'gce'
min_inv: .4

train:
  loss_coefficients: [ 1., 0.1 ]
  n_views: 2
  lr_scheduler:
    patience: 999
    trials: 0
    epoch_decay_start: 50
  resume: False
  retrain_resume: False
  policy_iter: best
  which_iter: warmup
  init_method: equal
  log_interval: 1
  val_interval: 1
  switch_core_no: 0
  coteaching:
    num_gradual: 20
    exponent: 1
    forget_rate: .4
    use_plus: False
    relax: False  # False True

arch:
  # inception
  num_blocks: 3
  out_channels: 64
  # resnet
  mid_channels: 32
  num_positions: 8

tensorboard:
  flush_secs: 10
  filename_suffix: ''

test:
  test_interval: 1
  which_iter: best

abstention:
  learn_epochs: 5
  abst_rate: 0.1
  alpha_final: 1.
  alpha_init_factor: 64.
  pid_tunings: [.1, .1, .05]
elr_alpha: 1
elr_beta: .7

